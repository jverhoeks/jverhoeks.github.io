<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>Jacobs Tech Blog - etl</title>
    <subtitle>Tech, Cloud and Programming</subtitle>
    <link rel="self" type="application/atom+xml" href="https://jacob.verhoeks.org/categories/etl/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://jacob.verhoeks.org"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2022-12-07T00:00:00+00:00</updated>
    <id>https://jacob.verhoeks.org/categories/etl/atom.xml</id>
    <entry xml:lang="en">
        <title>Data Engineering and ChatGPT (part2)</title>
        <published>2022-12-07T00:00:00+00:00</published>
        <updated>2022-12-07T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://jacob.verhoeks.org/dataengineering-and-chatgpt-part2-copy/"/>
        <id>https://jacob.verhoeks.org/dataengineering-and-chatgpt-part2-copy/</id>
        
        <summary type="html">&lt;p&gt;In my previous &lt;a href=&quot;..&#x2F;dataengineering-and-chatgpt&#x2F;&quot;&gt;post&lt;&#x2F;a&gt; i must have hit some issue with ChatGPT. It&#x27;s way more impressive then i thought..&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;question-1&quot;&gt;question 1&lt;&#x2F;h2&gt;
&lt;blockquote&gt;
&lt;p&gt;can you write a pyspark job that inserts data into an iceberg table&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Sure, here is an example of a PySpark job that inserts data into an iceberg table:&lt;&#x2F;p&gt;
</summary>
        
    </entry>
    <entry xml:lang="en">
        <title>Data Engineering and ChatGPT</title>
        <published>2022-12-06T00:00:00+00:00</published>
        <updated>2022-12-06T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://jacob.verhoeks.org/dataengineering-and-chatgpt/"/>
        <id>https://jacob.verhoeks.org/dataengineering-and-chatgpt/</id>
        
        <summary type="html">&lt;p&gt;ChatGPT is out and everybody is trying it.  Blogs, songs are easy, but can it help with Data Engineering?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;question-1&quot;&gt;question 1&lt;&#x2F;h2&gt;
&lt;blockquote&gt;
&lt;p&gt;i have a table  named &#x27;people&#x27; with fields: id, name, job_type and a table names &#x27;jobs&#x27; with fields: id,job_name. Create a join on this two tables in sql&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;To create a join on two tables in SQL, you can use the JOIN keyword. Here&#x27;s an example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;SELECT people.name, jobs.job_name
&lt;&#x2F;span&gt;&lt;span&gt;FROM people
&lt;&#x2F;span&gt;&lt;span&gt;INNER JOIN jobs ON people.job_type = jobs.id
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This query will return a table with columns name and job_name, and each row will represent a person and the job they have. The JOIN keyword is used to specify the tables to be joined, and the ON keyword is used to specify the criteria for matching rows in the two tables. In this case, the ON clause specifies that rows in the people table should be matched with rows in the jobs table based on the value of job_type in the people table and the value of id in the jobs table.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
</summary>
        
    </entry>
    <entry xml:lang="en">
        <title>Python and modules for ETL jobs on AWS</title>
        <published>2022-10-23T00:00:00+00:00</published>
        <updated>2022-10-23T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://jacob.verhoeks.org/etl-in-python/"/>
        <id>https://jacob.verhoeks.org/etl-in-python/</id>
        
        <summary type="html">&lt;p&gt;Python is a powerfull tool to run ETL jobs on AWS. The 3 main ways are Lambda, Glue (pyspark) and Glue Pythonshell.
Lambda can run max 15 minutes. Glue Pythonshell is a simple environment for run python scripts, the Glue Spark provides a full serverless PySpark environment to run complex scripts.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;other-systems&quot;&gt;Other systems&lt;&#x2F;h2&gt;
&lt;p&gt;There are many ways to run scripts on AWS, there are out of scope for now.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;AWS Batch&lt;&#x2F;li&gt;
&lt;li&gt;Fargate&lt;&#x2F;li&gt;
&lt;li&gt;EKS&lt;&#x2F;li&gt;
&lt;li&gt;Amazon Managed Workflows for Apache Airflow&lt;&#x2F;li&gt;
&lt;li&gt;anything custom.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;adding-packages-options&quot;&gt;Adding packages options&lt;&#x2F;h2&gt;
&lt;p&gt;While python is powerfull, you need additional libraries for your code. The most common for ETL processing are NumPy and Pandas. But many others are available for retrieving api&#x27;s, parsing files, etc.&lt;&#x2F;p&gt;
</summary>
        
    </entry>
    <entry xml:lang="en">
        <title>Secrets and AWS GLUE Custom Connectors</title>
        <published>2022-09-11T00:00:00+00:00</published>
        <updated>2022-09-11T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://jacob.verhoeks.org/secrets-and-aws-glue-custom-connectors/"/>
        <id>https://jacob.verhoeks.org/secrets-and-aws-glue-custom-connectors/</id>
        
        <summary type="html">&lt;p&gt;For a project i had to retrieve data from Teradata using a Glue Job. A quick google gave me this: &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.teradata.com&#x2F;Blogs&#x2F;Teradata-and-AWS-Glue&quot;&gt;Teradata Blog&lt;&#x2F;a&gt;
This uses the JDBC Connector and it gets the credentials from SecretsManager using some boto3 api-calls.&lt;&#x2F;p&gt;
&lt;p&gt;However Glue is evolving and with the release of AWS Glue Studio, the old style JDBC aren&#x27;t supported in it. It requires new Custom Connectors or Marketplace Connectors.&lt;&#x2F;p&gt;
&lt;p&gt;The documentation and many blogs still point to the old way, i wrote down here on how to use the new custom connectors in combination with SecretsManager. Hopefully saving other some time.&lt;&#x2F;p&gt;
</summary>
        
    </entry>
</feed>
